from tools import query_groq
from qdrant_client.models import VectorParams, Distance

from tools import query_groq
from dotenv import load_dotenv

import os
import csv
import openai
import uuid
from qdrant_client import QdrantClient
import nltk

# openai.api_type = "azure"
# openai.api_base = os.getenv("Azure_link")    # e.g., "https://YOUR-RESOURCE.openai.azure.com/"
# openai.api_key = os.getenv("Azure_OpenAI")          # Your Azure OpenAI Key
# openai.api_version = ""
from openai import AzureOpenAI

client = AzureOpenAI(
    api_key=os.getenv("Azure_OpenAI"),
    azure_endpoint=os.getenv("Azure_link"),
    api_version="2023-05-15"  # or the version you have access to
)

def get_embedding(text):
    response = client.embeddings.create(
        input=[text],
        model="embedding-model-name",  # e.g., "text-embedding-ada-002"
        deployment_id="your-deployment-id"  # Azure deployment name
    )
    return response.data[0].embedding

EMBEDDING_MODEL = "embed model name"  # Azure OpenAI embedding deployment
# COMPLETION_MODEL = "ychat completion model name (response model)"       # Azure OpenAI completion deployment

QDRANT_HOST = os.getenv("QDRANT-URL")  # e.g., "https://YOUR-QDRANT-URL
QDRANT_API_KEY = os.getenv("QDRANT_API")
COLLECTION = "rag_bot"

client = QdrantClient(
    url=QDRANT_HOST,
    api_key=QDRANT_API_KEY
)

# def get_embedding(text):
#     """Generate an embedding using Azure OpenAI."""
#     response = openai.Embedding.create(
#         input=[text],
#         engine=EMBEDDING_MODEL
#     )
#     return response["data"][0]["embedding"]

# def create_collection():
#     """Create or recreate the Qdrant collection."""
#     client.recreate_collection(
#         collection_name=COLLECTION,
#         vectors_config=VectorParams(size=384, distance=Distance.COSINE)#COSINE is  a method of similarity search select size accroding to dim of embed model
# # cool  what is size
#     )
    
    # def upload_vectors(index_data):
    #     """Upload data to Qdrant."""
    # points = []
    # for item in index_data:
    #     vector = get_embedding(item["chunk"])
    #     points.append(PointStruct(id=item["id"], vector=vector, payload=item))
    # client.upsert(collection_name=COLLECTION, points=points)

def get_top_chunks(query, k=5):
    """Retrieve the most relevant chunks from Qdrant."""
    # Use the imported get_embedding from populate_database.py for query embedding
    query_vector = get_embedding(query)
    results = client.query_points(
        collection_name=COLLECTION_NAME,
        query=query_vector,  # Changed from query_vector to query
        limit=k,
        with_payload=True
    )
    # Handle the results structure properly
    chunks = []
    # results is typically a QueryResponse object with a .points attribute
    points = getattr(results, 'points', results)
    if isinstance(points, list):
        for hit in points:
            payload = getattr(hit, "payload", None)
            if payload is None and isinstance(hit, dict):
                payload = hit.get("payload", {})
            if payload and "chunk" in payload:
                chunks.append(payload["chunk"])
    return chunks

recipient_context = {}

# Stack to track question and answer history for backtracking
question_stack = []


def generate_answer(query, chunks):
    """Use Azure OpenAI to generate an answer given retrieved chunks."""
    completion_client = AzureOpenAI(
        api_key=COMPLETION_API_KEY,
        api_version=AZURE_OPENAI_API_VERSION,
        azure_endpoint=COMPLETION_API_BASE
    )
    context = "\n".join(chunks)
    prompt = f"Context:\n{context}\n\nQuestion: {query}\nAnswer:"
    response = completion_client.chat.completions.create(
        model=COMPLETION_MODEL_NAME,
        messages=[{"role": "user", "content": prompt}],
        max_tokens=200
    )
    return response.choices[0].message.content

def ask_and_respond(question, prev_q=None, prev_a=None):
    # Build a one-paragraph natural question based on recipient context
    context_summary = "\n".join([f"{k.replace('_', ' ').capitalize()}: {v}" for k, v in recipient_context.items()])
     
    custom_prompt = (
        "You are a warm and creative assistant helping someone choose a thoughtful experience gift. "
        "You will rewrite the given question as a natural ,engaging prompt for the user and also respond warmly with 1 short sentence that shows understanding . "
        "IMPORTANT: Do NOT answer the question, do NOT add any explanations, introductions, or phrases like "
        "'Here's your rewritten prompt:' or 'That's a great question!'. "
        "Return ONLY the rewritten question prompt, with 40â€“60 words (2â€“3 sentences) in a single paragraph, based on the context below. "
        f"Original question: '{question}'\nContext:\n{context_summary}\n"
        "Make it concise, friendly, and conversational."
    )

    try:
        final_question = query_groq([{"role": "user", "content": (custom_prompt)}])
    except Exception as e:
        print("âŒ AI Question Generation Error:", e)
        final_question = question  # fallback

    # Ask the generated paragraph-question
    answer = input(f"{final_question}\n> ")

    # Store context
    import re
    safe_q = re.sub(r'[^\w\s]', '', question).strip().lower()
    key = '_'.join(safe_q.split())[:40]
    recipient_context[key] = answer
    question_stack.append((key, question, answer))

    # Generate a follow-up conversational comment
    context_summary = "\n".join([f"{k.replace('_', ' ').capitalize()}: {v}" for k, v in recipient_context.items()])
    # response_prompt = (
    #     f"You are helping someone choose a gift experience. Here's what you know so far:\n{context_summary}\n"
    #     f"Respond briefly and conversationally to their answer: '{answer}'"
    # )
    # messages = [{"role": "user", "content": response_prompt}]
    # try:
    #     ai_response = query_groq(messages)
    #     print(f"ğŸ¤– {ai_response}\n")
    # except Exception as e:
    #     print("âŒ AI Error:", e)

    return question, answer
def go_back():
    """Go back to the previous question by removing the last entry from recipient_context and question_stack."""
    if not question_stack:
        return {"error": "No previous question to go back to."}
    key, question, answer = question_stack.pop()
    if key in recipient_context:
        del recipient_context[key]
    return {"question": question, "answer": answer}

import random

# Multiple variations for each question to add randomness and freshness
questions_alternatives = [
    [
        "Tell me a bit about your relationship with the person you're giftingâ€”are they a close friend, partner, sibling, or someone else?",
        "How would you describe your connection with the person youâ€™re planning to surprise?",
        "Who is the gift for, and what kind of bond do you shareâ€”friendship, family, love, or something else?",
        "Whatâ€™s your relationship with this personâ€”are they someone you see daily or reconnect with on special occasions?"
    ],
    [
        "What's the special occasion or reason behind this giftâ€”birthday, anniversary, celebration, or just a surprise?",
        "Whatâ€™s the occasion for this giftâ€”something planned or a spontaneous surprise?",
        "Is this gift for a birthday, milestone, or just a â€˜thinking of youâ€™ kind of moment?",
        "Are you celebrating anything specific with this gift, or is it just to brighten their day?"
    ],
    [
        "If you had to describe their vibe or personality in a few wordsâ€”like adventurous, calm, creative, or foodieâ€”what would you say?",
        "What kind of energy or personality does the recipient bringâ€”are they outgoing, introverted, artistic, or a thrill-seeker?",
        "How would you sum up their style or interests? Outdoorsy, luxury-loving, chill, high-energy?",
        "Give me a quick sense of their personalityâ€”what makes them light up?"
    ],
    [
        "Whatâ€™s the general budget youâ€™re planning to spend on this experience gift?",
        "Roughly how much would you like to spend on this experience?",
        "Do you have a price range in mind for this gift?",
        "Are you going for something small and sweet, or are you open to something more premium?"
    ],
    [
        "Is there a specific city or region youâ€™d like the experience to take place in, or should it be something flexible or online?",
        "Where should this experience happen? In a specific city or should it be open to anywhereâ€”or even virtual?",
        "Do you have a location in mind for the experience, or would you prefer something flexible or remote?",
        "Would you like the experience to be tied to a specific place, or is flexibility more important?"
    ]
]

def collect_gift_info():
    answers = []
    prev_q = prev_a = None
    for alternatives in questions_alternatives:
        q = random.choice(alternatives)
        qa = ask_and_respond(q, prev_q, prev_a)
        answers.append(qa)
        prev_q, prev_a = qa
    return answers

def format_final_prompt():
    prompt = "You are a creative and thoughtful assistant helping someone choose a unique experience gift. Based on the following details, suggest one highly relevant experience with a short reason:\n\n"
    for key, value in recipient_context.items():
        prompt += f"{key.replace('_', ' ').capitalize()}: {value}\n"
    prompt += "\nKeep it concise but vivid."
    return prompt

def follow_up_chat():
    print("ğŸ—¨ï¸ You can now ask any follow-up questions about the gift or recipient. Type 'exit' to end.")
    while True:
        user_q = input("> ")
        if user_q.strip().lower() in ["exit", "quit"]:
            print("ğŸ‘‹ Thanks for using the gifting assistant. Happy gifting!")
            break
        # Add context memory
        context = "\n".join([f"{k.replace('_', ' ').capitalize()}: {v}" for k, v in recipient_context.items()])
        messages = [{"role": "user", "content": f"Here is what we know about the recipient:\n{context}\nUser question: {user_q}"}]
        try:
            answer = query_groq(messages)
            print("ğŸ¤–", answer)
        except Exception as e:
            print("âŒ Error:", e)

def run_this():
    
    print("ğŸ“ Let's start with some quick questions to get to know the recipient better.\n")
    collect_gift_info()
    
    final_prompt = format_final_prompt()
    print("\nğŸ¯ Based on your answers, here's the final prompt for the AI:\n")
    print(final_prompt)
    
    print("\nğŸ’¡ Now let's see what unique experience gift the AI suggests...")
    print(final_prompt)
    try:
        ai_suggestion = query_groq([{"role": "user", "content": final_prompt}])
        print("ğŸ¤– AI Suggestion:", ai_suggestion)
    except Exception as e:
        print("âŒ AI Suggestion Error:", e)

    follow_up_chat()

if __name__ == "__main__":
    print("ğŸ Welcome to the Experience Gifting Assistant!\nI'll ask a few quick questions to help you find the perfect gift.\n")
    run_this()
